from flask import Flask, render_template, request, jsonify, Response
import json
import random
from pathlib import Path
# import google.generativeai as genai # å¼•å…¥ Gemini SDK
from google import genai

# --- è¨­å®š Gemini API ---
# âš ï¸ æ³¨æ„ï¼šå°‡ä½ çš„ API é‡‘é‘°å­˜åœ¨ç’°å¢ƒè®Šæ•¸ä¸­ï¼Œè€Œéç›´æ¥å¯«åœ¨ç¨‹å¼ç¢¼è£¡
import os
# å¦‚æœæ²’æœ‰è¨­å®šç’°å¢ƒè®Šæ•¸ï¼Œé€™è£¡æœƒå‡ºéŒ¯ï¼Œæ‰€ä»¥è¦å…ˆè¨­å®šå¥½
# genai.configure(api_key=os.environ.get("GEMINI_API_KEY")) 
# é¸æ“‡ä¸€å€‹é©åˆçš„æ¨¡å‹ï¼Œä¾‹å¦‚ 'gemini-1.5-flash-latest'
# model = genai.GenerativeModel('gemini-2.5-flash')
# ---

client = genai.Client()
MODEL = "gemini-2.5-flash"

app = Flask(__name__)

# æ¨¡æ“¬ä¸€å€‹å„²å­˜ç´¯ç© token æ•¸çš„è®Šæ•¸
total_tokens_used = 0

# å…¨åŸŸè³‡æ–™
questions = []
wrong_questions = []
marked_questions = []
question_index = 0
remaining_questions_order = []
remaining_questions_random = []

answered_questions = set()

# æ–°å¢ï¼šå»ºç«‹ä¸€å€‹å…¨åŸŸå¿«å–å­—å…¸ä¾†å„²å­˜ AI è©³è§£
ai_explanation_cache = {}

@app.route("/")
def index():
    # å‚³éæ‰€æœ‰é¡Œè™Ÿçµ¦å‰ç«¯ï¼Œä»¥ä¾¿ç”Ÿæˆä¸‹æ‹‰é¸å–®
    all_question_ids = [q.get("é¡Œè™Ÿ") for q in questions]
    return render_template("index.html", all_question_ids=all_question_ids, total_questions=len(questions))

@app.route("/review")
def review():
    return render_template("review.html", wrong_questions=wrong_questions)

@app.route("/review_marked")
def review_marked():
    return render_template("review_marked.html", marked_questions=marked_questions)

@app.route("/get_question")
def get_question():
    global question_index, remaining_questions_order, remaining_questions_random
    mode = request.args.get("mode", "random")
    question_id = request.args.get("question_id")

    if not questions:
        return jsonify({"error": "é¡Œåº«å°šæœªè¼‰å…¥"})

    # è™•ç†è·³è½‰åˆ°ç‰¹å®šé¡Œè™Ÿçš„è«‹æ±‚
    if question_id:
        try:
            jump_index = next(i for i, q in enumerate(questions) if q.get("é¡Œè™Ÿ") == question_id)
            question_index = jump_index
            
            if mode == "order":
                remaining_questions_order = questions[question_index:]

            q = questions[question_index]
            # ä¿®æ­£ï¼šé€éé¡Œè™Ÿåˆ¤æ–·é¡Œç›®æ˜¯å¦å·²è¢«æ¨™è¨˜
            q["is_marked"] = any(marked_q.get("é¡Œè™Ÿ") == q.get("é¡Œè™Ÿ") for marked_q in marked_questions)
            q["is_multiple"] = True if q.get("é¡Œåˆ¥") == "è¤‡" else False
            question_index += 1
            return jsonify(q)
        except StopIteration:
            return jsonify({"error": f"æ‰¾ä¸åˆ°é¡Œè™Ÿç‚º {question_id} çš„é¡Œç›®"})

    # ä»¥ä¸‹æ˜¯è™•ç†æ­£å¸¸å‡ºé¡Œæ¨¡å¼çš„é‚è¼¯
    if mode == "order" and not remaining_questions_order:
        remaining_questions_order = list(questions)
        question_index = 0
    elif mode == "random" and not remaining_questions_random:
        remaining_questions_random = list(questions)
        random.shuffle(remaining_questions_random)
    elif mode == "wrong" and not wrong_questions:
        return jsonify({"error": "ç›®å‰æ²’æœ‰éŒ¯é¡Œ"})

    q = None
    if mode == "random":
        if remaining_questions_random:
            q = remaining_questions_random.pop(0)
    elif mode == "order":
        if remaining_questions_order:
            q = remaining_questions_order[question_index]
            question_index += 1
    elif mode == "wrong":
        if wrong_questions:
            q = random.choice(wrong_questions)

    if q is None:
        return jsonify({"error": "æ‰€æœ‰é¡Œç›®éƒ½å·²å‡ºå®Œï¼", "finished": True})

    # ä¿®æ­£ï¼šç¢ºä¿æ‰€æœ‰å›å‚³é¡Œç›®çš„åˆ¤æ–·æ–¹å¼ä¸€è‡´
    q["is_marked"] = any(marked_q.get("é¡Œè™Ÿ") == q.get("é¡Œè™Ÿ") for marked_q in marked_questions)
    q["is_multiple"] = True if q.get("é¡Œåˆ¥") == "è¤‡" else False
    print(q["is_multiple"])
    return jsonify(q)

@app.route("/submit_answer", methods=["POST"])
def submit_answer():
    data = request.json
    q = data["question"]
    answer = data["answer"].strip().upper()

    correct = q.get("ç­”æ¡ˆ", "").strip().upper()
    is_correct = (answer == correct)

    if not is_correct:
        if q not in wrong_questions:
            wrong_questions.append(q)

    answered_questions.add(q.get("é¡Œè™Ÿ"))
    return jsonify({
        "correct": is_correct,
        "right_answer": correct,
        "answered_count": "{}/{}".format(len(answered_questions), len(questions)) if questions else len(answered_questions)
    })

@app.route("/mark_question", methods=["POST"])
def mark_question():
    data = request.json
    q = data["question"]
    # å„²å­˜é¡Œè™Ÿï¼Œè€Œä¸æ˜¯æ•´å€‹é¡Œç›®ç‰©ä»¶
    if q.get("é¡Œè™Ÿ") not in [mq.get("é¡Œè™Ÿ") for mq in marked_questions]:
        marked_questions.append(q)
    return jsonify({"status": "marked"})

@app.route("/reset_questions", methods=["POST"])
def reset_questions():
    global remaining_questions_order, remaining_questions_random, question_index
    remaining_questions_order = list(questions)
    remaining_questions_random = list(questions)
    random.shuffle(remaining_questions_random)
    question_index = 0
    answered_questions.clear()
    return jsonify({"status": "reset"})

@app.route("/get_ai_explanation", methods=["POST"])
def get_ai_explanation():
    global total_tokens_used
    data = request.json
    question = data.get("question")

    if not question:
        return jsonify({"error": "æœªæä¾›é¡Œç›®"}), 400
    
    question_id = question["é¡Œè™Ÿ"]

    # æ­¥é©Ÿ 1: æª¢æŸ¥å¿«å–ä¸­æ˜¯å¦æœ‰è©³è§£
    if question_id in ai_explanation_cache:
        print(f"âœ… é¡Œè™Ÿ {question_id} çš„è©³è§£å·²å¾å¿«å–ä¸­å–å¾—ã€‚")
        explanation = ai_explanation_cache[question_id]
        return jsonify({
            "explanation": explanation,
            "current_tokens": 0,  # å¾å¿«å–ä¸­å–å¾—ï¼Œä¸è¨ˆç®— token æ•¸
            "total_tokens": total_tokens_used
        })

    # æ­¥é©Ÿ 2: å¦‚æœå¿«å–ä¸­æ²’æœ‰ï¼Œå‰‡åŸ·è¡Œ API å‘¼å«

    prompt = f"è«‹ä»¥ç¹é«”ä¸­æ–‡ï¼Œé‡å°ä»¥ä¸‹å•é¡Œæä¾›è©³ç´°çš„è§£é‡‹ï¼š\n\né¡Œç›®ï¼š{question['é¡Œç›®']}\né¸é …ï¼š{' '.join(question['é¸é …'])}\nç­”æ¡ˆï¼š{question['ç­”æ¡ˆ']}"
    
    try:
        # response = model.generate_content(prompt)
        response = client.models.generate_content(
            model=MODEL,
            contents=prompt,
        )
        # ç§»é™¤é€™è¡Œç¨‹å¼ç¢¼ï¼Œè®“ AI å›å‚³çš„æ›è¡Œå’Œæ ¼å¼å¾—ä»¥ä¿ç•™
        explanation = response.text

        # æ­¥é©Ÿ 3: å°‡æ–°çš„è©³è§£å„²å­˜åˆ°å¿«å–ä¸­
        ai_explanation_cache[question_id] = explanation
        
        # è¨ˆç®—æœ¬æ¬¡è«‹æ±‚çš„ token æ•¸
        prompt_tokens = response.usage_metadata.prompt_token_count
        completion_tokens = response.usage_metadata.prompt_token_count
        current_tokens = prompt_tokens + completion_tokens
        
        # æ›´æ–°ç´¯ç© token æ•¸
        total_tokens_used += current_tokens

        return jsonify({
            "explanation": explanation,
            "current_tokens": current_tokens,
            "total_tokens": total_tokens_used
        })
    except Exception as e:
        print(f"Gemini API å‘¼å«å¤±æ•—: {e}")
        return jsonify({"error": "ç„¡æ³•å–å¾— AI è©³è§£ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"}), 500
    
# æ–°å¢ä¸€å€‹ç”¨æ–¼ä¸²æµå›æ‡‰çš„è·¯ç”±
@app.route("/stream_ai_explanation", methods=["POST"])
def stream_ai_explanation():
    global total_tokens_used
    data = request.json
    question = data.get("question")

    if not question:
        return jsonify({"error": "æœªæä¾›é¡Œç›®"}), 400
    
    question_id = question["é¡Œè™Ÿ"]

    # æ­¥é©Ÿ 1: æª¢æŸ¥å¿«å–ä¸­æ˜¯å¦æœ‰è©³è§£
    if question_id in ai_explanation_cache:
        print(f"âœ… é¡Œè™Ÿ {question_id} çš„è©³è§£å·²å¾å¿«å–ä¸­å–å¾—ã€‚")
        explanation = ai_explanation_cache[question_id]
        return jsonify({
            "explanation": explanation,
            "current_tokens": 0,  # å¾å¿«å–ä¸­å–å¾—ï¼Œä¸è¨ˆç®— token æ•¸
            "total_tokens": total_tokens_used
        })

    prompt = f"è«‹ä»¥ç¹é«”ä¸­æ–‡ï¼Œé‡å°ä»¥ä¸‹å•é¡Œæä¾›è©³ç´°çš„è§£é‡‹ï¼š\n\né¡Œç›®ï¼š{question['é¡Œç›®']}\né¸é …ï¼š{' '.join(question['é¸é …'])}\nç­”æ¡ˆï¼š{question['ç­”æ¡ˆ']}"
    
    # ç¢ºä¿ prompt_tokens åœ¨ä¸²æµé–‹å§‹å‰è¨ˆç®—ä¸€æ¬¡
    # å› ç‚º prompt tokens åœ¨ç™¼é€è«‹æ±‚æ™‚å°±å·²ç¢ºå®š
    prompt_tokens = client.models.count_tokens(prompt).total_tokens

    def generate_stream():
        try:
            # å‘¼å« genai API ä¸¦å•Ÿç”¨ä¸²æµ
            for chunk in client.models.generate_content(
                model=MODEL, contents=prompt, stream=True):
                # å°‡æ¯å€‹å›æ‡‰ç‰‡æ®µçš„æ–‡å­—ä»¥ utf-8 ç·¨ç¢¼
                text_chunk = chunk.text
                if (text_chunk):
                    yield text_chunk.encode('utf-8')

                # å„²å­˜æœ€å¾Œä¸€å€‹ chunk çš„ä½¿ç”¨å…ƒæ•¸æ“š
                last_chunk_metadata = chunk.usage_metadata
            
            # ä¸²æµçµæŸå¾Œï¼Œå¾æœ€å¾Œä¸€å€‹ chunk å–å¾— Completion Token æ•¸
            if last_chunk_metadata:
                completion_tokens = last_chunk_metadata.completion_token_count
            
            # ç¸½çµ Token è³‡è¨Šä¸¦ä»¥ JSON æ ¼å¼å‚³é€
            token_info = {
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens
            }
            
            # å°‡ JSON è³‡è¨Šå‚³é€çµ¦å‰ç«¯
            yield f"<div data-tokens='{json.dumps(token_info)}' style='display:none;'></div>".encode('utf-8')

        except Exception as e:
            # è™•ç†å¯èƒ½ç™¼ç”Ÿçš„ API éŒ¯èª¤
            error_message = f"ç„¡æ³•å–å¾— AI è©³è§£ï¼š{e}"
            yield f'<p style="color:red;">{error_message}</p>'.encode('utf-8')

    # é€™è£¡å›å‚³ Response ç‰©ä»¶ï¼Œä¸¦å°‡ç”Ÿæˆå™¨å‡½å¼ä½œç‚ºå›æ‡‰å…§å®¹
    # mimetype è¨­ç‚º text/htmlï¼Œè®“ç€è¦½å™¨èƒ½ç›´æ¥è§£æ HTML æ¨™ç±¤
    return Response(generate_stream(), mimetype='text/html')

def load_questions(json_paths):
    global questions, remaining_questions_order, remaining_questions_random
    all_question_files = []
    
    for path_str in json_paths:
        p = Path(path_str)
        if not p.exists():
            print(f"âŒ æ‰¾ä¸åˆ°è·¯å¾‘ï¼š{path_str}")
            continue

        if p.is_dir():
            # å¦‚æœæ˜¯è³‡æ–™å¤¾ï¼Œå°‹æ‰¾æ‰€æœ‰ .json æª”æ¡ˆ
            print(f"ğŸ“‚ æ­£åœ¨è¼‰å…¥è³‡æ–™å¤¾ï¼š{p}")
            all_question_files.extend(p.glob("*.json"))
        else:
            # å¦‚æœæ˜¯å–®ä¸€æª”æ¡ˆï¼Œç›´æ¥åŠ å…¥åˆ—è¡¨
            all_question_files.append(p)

    all_questions = []
    for file_path in all_question_files:
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                if isinstance(data, list):
                    cleaned_questions = []
                    for q in data:
                        if 'é¡Œç›®' in q:
                            q['é¡Œç›®'] = q['é¡Œç›®'].replace('\r\n', ' ').replace('\n', ' ').strip()
                        if 'é¸é …' in q and isinstance(q['é¸é …'], list):
                            q['é¸é …'] = [opt.replace('\r\n', ' ').replace('\n', ' ').strip() for opt in q['é¸é …']]
                        if 'é¡Œè™Ÿ' in q:
                            q['é¡Œè™Ÿ'] = f"{file_path.stem}_{q.get('é¡Œè™Ÿ')}"
                        cleaned_questions.append(q)
                    all_questions.extend(cleaned_questions)
                    print(f"âœ… è¼‰å…¥æª”æ¡ˆï¼š{file_path}ï¼Œé¡Œæ•¸ï¼š{len(cleaned_questions)}")
                else:
                    print(f"âš ï¸ {file_path} æ ¼å¼éŒ¯èª¤ï¼Œéé™£åˆ—ï¼Œç•¥é")
        except json.JSONDecodeError:
            print(f"âš ï¸ {file_path} ç„¡æ³•è§£æç‚º JSONï¼Œç•¥é")
        except Exception as e:
            print(f"âŒ è™•ç†æª”æ¡ˆ {file_path} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
            
    questions = all_questions
    remaining_questions_order = list(questions)
    remaining_questions_random = list(questions)
    random.shuffle(remaining_questions_random)

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="åœ‹è€ƒå‡ºé¡Œæ©Ÿï¼ˆæ”¯æ´å¤šé¡Œåº«èˆ‡æ¨¡å¼åˆ‡æ›ï¼‰")
    parser.add_argument("json_files", nargs="+", help="ä¸€å€‹æˆ–å¤šå€‹é¡Œåº« JSON æª”æ¡ˆæˆ–è³‡æ–™å¤¾")
    parser.add_argument("--host", default="127.0.0.1")
    parser.add_argument("--port", default=5000, type=int)
    args = parser.parse_args()

    load_questions(args.json_files)
    print(f"âœ… é¡Œåº«å·²è¼‰å…¥ï¼Œç¸½é¡Œæ•¸ï¼š{len(questions)}")
    print(f"ğŸŒ ç¶²é å‡ºé¡Œæ©Ÿï¼šhttp://{args.host}:{args.port}")
    app.run(host=args.host, port=args.port, debug=True)